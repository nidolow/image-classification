{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nidolow/image-classification/blob/master/notebooks/train_exp.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize\n",
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KdFMnpmUjs7O"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select data location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KdFMnpmUjs7O"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    DATA_PATH = '/content/drive/My Drive/train/'\n",
    "    OUTPUT_DIR = '/content/drive/My Drive/train/'\n",
    "except:\n",
    "    DATA_PATH = '../data/train/'\n",
    "    OUTPUT_DIR = '../models/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KdFMnpmUjs7O"
   },
   "outputs": [],
   "source": [
    "CONF = {\n",
    "    'batch': 128,\n",
    "    'max_epochs': 15,\n",
    "    'height': 128,\n",
    "    'width': 128,\n",
    "    'features': {}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_GPU_MEM = 1536\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if False: # Better GPU works fine with no restrictions\n",
    "    # Restrict TensorFlow to only allocate limited amount of memory on the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=MAX_GPU_MEM)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manage input data\n",
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KdFMnpmUjs7O"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading category: human\n",
      "Loading category: dog\n",
      "Loading category: cat\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "for category in os.listdir(DATA_PATH):\n",
    "    print('Loading category:', category)\n",
    "    filenames = [os.path.join(category, f) for f in os.listdir(os.path.join(DATA_PATH, category))]\n",
    "    df = pd.concat([df,\n",
    "                    pd.DataFrame({'filename': filenames,\n",
    "                                  'category': category})])\n",
    "\n",
    "train_df, validation_df = train_test_split(df, test_size=0.10, random_state=29)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KdFMnpmUjs7O"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 31708 validated image filenames belonging to 3 classes.\n",
      "Found 3524 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_data = train_generator.flow_from_dataframe(\n",
    "    train_df,\n",
    "    DATA_PATH,\n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    batch_size=CONF['batch'],\n",
    "    target_size=(CONF['height'], CONF['width']),\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_data = validation_generator.flow_from_dataframe(\n",
    "    validation_df,\n",
    "    DATA_PATH,\n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    batch_size=CONF['batch'],\n",
    "    target_size=(CONF['height'], CONF['width']),\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KdFMnpmUjs7O",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 128, 128, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               8389120   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 8,414,243\n",
      "Trainable params: 8,414,243\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(16, 3, padding='same', activation='relu', input_shape=(CONF['height'], CONF['width'], 3)),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(3, activation='softmax')])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "CONF['model'] = json.loads(model.to_json())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KdFMnpmUjs7O"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 247 steps, validate for 27 steps\n",
      "Epoch 1/15\n",
      "247/247 [==============================] - 60s 244ms/step - loss: 0.5431 - accuracy: 0.7344 - val_loss: 0.3737 - val_accuracy: 0.8171\n",
      "Epoch 2/15\n",
      "247/247 [==============================] - 60s 242ms/step - loss: 0.3377 - accuracy: 0.8389 - val_loss: 0.3242 - val_accuracy: 0.8446\n",
      "Epoch 3/15\n",
      "247/247 [==============================] - 60s 242ms/step - loss: 0.2856 - accuracy: 0.8703 - val_loss: 0.3023 - val_accuracy: 0.8608\n",
      "Epoch 4/15\n",
      "247/247 [==============================] - 60s 243ms/step - loss: 0.2546 - accuracy: 0.8857 - val_loss: 0.2926 - val_accuracy: 0.8672\n",
      "Epoch 5/15\n",
      "247/247 [==============================] - 60s 242ms/step - loss: 0.2161 - accuracy: 0.9065 - val_loss: 0.3156 - val_accuracy: 0.8643\n",
      "Epoch 6/15\n",
      "247/247 [==============================] - 60s 243ms/step - loss: 0.1806 - accuracy: 0.9237 - val_loss: 0.2987 - val_accuracy: 0.8796\n",
      "Epoch 7/15\n",
      "247/247 [==============================] - 60s 243ms/step - loss: 0.1452 - accuracy: 0.9399 - val_loss: 0.3215 - val_accuracy: 0.8759\n",
      "Epoch 8/15\n",
      "247/247 [==============================] - 60s 242ms/step - loss: 0.0983 - accuracy: 0.9614 - val_loss: 0.3522 - val_accuracy: 0.8767\n",
      "Epoch 9/15\n",
      "247/247 [==============================] - 61s 246ms/step - loss: 0.0654 - accuracy: 0.9751 - val_loss: 0.4378 - val_accuracy: 0.8738\n",
      "Epoch 10/15\n",
      "247/247 [==============================] - 61s 248ms/step - loss: 0.0388 - accuracy: 0.9863 - val_loss: 0.5580 - val_accuracy: 0.8634\n",
      "Epoch 11/15\n",
      "247/247 [==============================] - 60s 241ms/step - loss: 0.0290 - accuracy: 0.9904 - val_loss: 0.5382 - val_accuracy: 0.8675\n",
      "Epoch 12/15\n",
      "247/247 [==============================] - 60s 242ms/step - loss: 0.0132 - accuracy: 0.9965 - val_loss: 0.6903 - val_accuracy: 0.8681\n",
      "Epoch 13/15\n",
      "247/247 [==============================] - 60s 244ms/step - loss: 0.0239 - accuracy: 0.9917 - val_loss: 0.6943 - val_accuracy: 0.8643\n",
      "Epoch 14/15\n",
      "247/247 [==============================] - 60s 242ms/step - loss: 0.0235 - accuracy: 0.9927 - val_loss: 0.6264 - val_accuracy: 0.8753\n",
      "Epoch 15/15\n",
      "247/247 [==============================] - 60s 243ms/step - loss: 0.0109 - accuracy: 0.9970 - val_loss: 0.7492 - val_accuracy: 0.8660\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_data,\n",
    "    steps_per_epoch=len(train_df) // CONF['batch'],\n",
    "    epochs=CONF['max_epochs'],\n",
    "    validation_data=validation_data,\n",
    "    validation_steps=len(validation_df) // CONF['batch'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash = str(hashlib.md5(json.dumps(CONF, sort_keys = True).encode(\"utf-8\")).hexdigest()[0:7])\n",
    "\n",
    "model.save_weights(os.path.join(OUTPUT_DIR, 'model-'+hash+'.mdl'))\n",
    "with open(os.path.join(OUTPUT_DIR, 'model-'+hash+'.history'), 'w') as w:\n",
    "    pd.DataFrame(history.history).to_json(w)\n",
    "with open(os.path.join(OUTPUT_DIR, 'model-'+hash+'.conf'), 'w') as w:\n",
    "    json.dump(CONF, w)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "dev0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
