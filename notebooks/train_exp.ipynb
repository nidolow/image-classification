{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nidolow/image-classification/blob/master/notebooks/train_exp.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize\n",
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KdFMnpmUjs7O"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, BatchNormalization, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select data location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KdFMnpmUjs7O"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    DATA_PATH = '/content/drive/My Drive/train/'\n",
    "    OUTPUT_DIR = '/content/drive/My Drive/train/'\n",
    "except:\n",
    "    DATA_PATH = '../data/train/'\n",
    "    OUTPUT_DIR = '../models/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KdFMnpmUjs7O"
   },
   "outputs": [],
   "source": [
    "CONF = {\n",
    "    'batch': 128,\n",
    "    'max_epochs': 15,\n",
    "    'height': 128,\n",
    "    'width': 128,\n",
    "    'features': {\n",
    "        'early_stop': True,\n",
    "        'batch_norm': False,\n",
    "        'dropout': True\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_GPU_MEM = 1536\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if False: # Better GPU works fine with no restrictions\n",
    "    # Restrict TensorFlow to only allocate limited amount of memory on the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=MAX_GPU_MEM)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manage input data\n",
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KdFMnpmUjs7O"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading category: human\n",
      "Loading category: dog\n",
      "Loading category: cat\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "for category in os.listdir(DATA_PATH):\n",
    "    print('Loading category:', category)\n",
    "    filenames = [os.path.join(category, f) for f in os.listdir(os.path.join(DATA_PATH, category))]\n",
    "    df = pd.concat([df,\n",
    "                    pd.DataFrame({'filename': filenames,\n",
    "                                  'category': category})])\n",
    "\n",
    "train_df, validation_df = train_test_split(df, test_size=0.10, random_state=29)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KdFMnpmUjs7O"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 31708 validated image filenames belonging to 3 classes.\n",
      "Found 3524 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_data = train_generator.flow_from_dataframe(\n",
    "    train_df,\n",
    "    DATA_PATH,\n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    batch_size=CONF['batch'],\n",
    "    target_size=(CONF['height'], CONF['width']),\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_data = validation_generator.flow_from_dataframe(\n",
    "    validation_df,\n",
    "    DATA_PATH,\n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    batch_size=CONF['batch'],\n",
    "    target_size=(CONF['height'], CONF['width']),\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KdFMnpmUjs7O",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 128, 128, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               8389120   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 8,414,243\n",
      "Trainable params: 8,414,243\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, 3, padding='same', activation='relu', input_shape=(CONF['height'], CONF['width'], 3)))\n",
    "if CONF['features']['batch_norm']: model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D())\n",
    "if CONF['features']['dropout']: model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(32, 3, padding='same', activation='relu'))\n",
    "if CONF['features']['batch_norm']: model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D())\n",
    "if CONF['features']['dropout']: model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, 3, padding='same', activation='relu'))\n",
    "if CONF['features']['batch_norm']: model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D())\n",
    "if CONF['features']['dropout']: model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "if CONF['features']['dropout']: model.add(Dropout(0.25))\n",
    "if CONF['features']['batch_norm']: model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "CONF['model'] = json.loads(model.to_json())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KdFMnpmUjs7O"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 247 steps, validate for 27 steps\n",
      "Epoch 1/15\n",
      "247/247 [==============================] - 60s 243ms/step - loss: 0.6674 - accuracy: 0.6744 - val_loss: 0.3979 - val_accuracy: 0.8079\n",
      "Epoch 2/15\n",
      "247/247 [==============================] - 60s 242ms/step - loss: 0.3824 - accuracy: 0.8111 - val_loss: 0.3534 - val_accuracy: 0.8232\n",
      "Epoch 3/15\n",
      "247/247 [==============================] - 59s 241ms/step - loss: 0.3295 - accuracy: 0.8440 - val_loss: 0.3279 - val_accuracy: 0.8458\n",
      "Epoch 4/15\n",
      "247/247 [==============================] - 60s 242ms/step - loss: 0.3068 - accuracy: 0.8580 - val_loss: 0.3061 - val_accuracy: 0.8576\n",
      "Epoch 5/15\n",
      "247/247 [==============================] - 60s 242ms/step - loss: 0.2797 - accuracy: 0.8720 - val_loss: 0.2989 - val_accuracy: 0.8634\n",
      "Epoch 6/15\n",
      "247/247 [==============================] - 60s 244ms/step - loss: 0.2635 - accuracy: 0.8814 - val_loss: 0.2765 - val_accuracy: 0.8776\n",
      "Epoch 7/15\n",
      "247/247 [==============================] - 60s 241ms/step - loss: 0.2394 - accuracy: 0.8927 - val_loss: 0.2703 - val_accuracy: 0.8767\n",
      "Epoch 8/15\n",
      "247/247 [==============================] - 60s 241ms/step - loss: 0.2216 - accuracy: 0.9027 - val_loss: 0.2607 - val_accuracy: 0.8851\n",
      "Epoch 9/15\n",
      "247/247 [==============================] - 60s 242ms/step - loss: 0.2007 - accuracy: 0.9135 - val_loss: 0.2708 - val_accuracy: 0.8874\n",
      "Epoch 10/15\n",
      "247/247 [==============================] - 59s 241ms/step - loss: 0.1780 - accuracy: 0.9250 - val_loss: 0.2683 - val_accuracy: 0.8866\n",
      "Epoch 11/15\n",
      "247/247 [==============================] - 60s 241ms/step - loss: 0.1544 - accuracy: 0.9362 - val_loss: 0.2792 - val_accuracy: 0.8880\n"
     ]
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    steps_per_epoch=len(train_df) // CONF['batch'],\n",
    "    epochs=CONF['max_epochs'],\n",
    "    validation_data=validation_data,\n",
    "    validation_steps=len(validation_df) // CONF['batch'],\n",
    "    callbacks=[early_stop])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash = str(hashlib.md5(json.dumps(CONF, sort_keys = True).encode(\"utf-8\")).hexdigest()[0:7])\n",
    "\n",
    "model.save_weights(os.path.join(OUTPUT_DIR, 'model-'+hash+'.mdl'))\n",
    "with open(os.path.join(OUTPUT_DIR, 'model-'+hash+'.history'), 'w') as w:\n",
    "    pd.DataFrame(history.history).to_json(w)\n",
    "with open(os.path.join(OUTPUT_DIR, 'model-'+hash+'.conf'), 'w') as w:\n",
    "    json.dump(CONF, w)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "dev0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
